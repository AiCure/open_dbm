{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.autograd as autograd\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import os\n",
    "from os.path import expanduser, join, exists\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from data.oflow_fp_dl import OflowDlDataset\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, os.path.expanduser('~/Code/cutils'))  \n",
    "from path_util import mkdir_p, save_pkl\n",
    "\n",
    "from datetime import datetime\n",
    "import pytz\n",
    "\n",
    "\n",
    "# In[3]:\n",
    "\n",
    "\n",
    "#GPU \n",
    "cuda = torch.cuda.is_available()\n",
    "num_gpus = torch.cuda.device_count()\n",
    "#num_gpus = 1\n",
    "\n",
    "root_path = expanduser('~/Data/tremor_hand_of/fp_uv_segments/')\n",
    "pkl_root = join(root_path, 'segment_16frame')\n",
    "data_info_path = join(root_path, 'freq_label_dic.json')\n",
    "\n",
    "test_pids = ['P005']\n",
    "val_pids =['P024', 'P025', 'P026', 'P029']\n",
    "\n",
    "it_tolerance = 200\n",
    "start_it = 0\n",
    "\n",
    "test_str = '_'.join(sorted(test_pids))\n",
    "val_str = '_'.join(val_pids)\n",
    "\n",
    "train_fpath = join(root_path, 'dl_amp_5_pos_1-29pts-Test_{}-Val_{}_train.pkl'.format(test_str, val_str))\n",
    "val_fpath = join(root_path, 'dl_amp_5_pos_1-29pts-Test_{}-Val_{}_val.pkl'.format(test_str, val_str))\n",
    "test_fpath = join(root_path, 'dl_amp_5_pos_1-29pts-Test_{}-Val_{}_test.pkl'.format(test_str, val_str))\n",
    "\n",
    "model_name = 'fp_z10_classifyOnly_29pts_3boosts_Test_{}_Val_{}'.format(test_str, val_str)\n",
    "model_path = expanduser('~/myData/aae/model_{}'.format(model_name))\n",
    "mkdir_p(model_path)\n",
    "\n",
    "cont_model_fpath = join(model_path, \"{}_{}_\".format(model_name, start_it) + \"{}_latest.pt\")\n",
    "\n",
    "init_model_fpath = expanduser('~/Data/tremor_hand_pretrained_models/init_models/init_z10_cls_9freq_200_Q_latest.pt') \n",
    "gen_model_fpath = expanduser('~/Data/tremor_hand_pretrained_models/generator/gen_fp_z10_excl_alltest_1700_P_latest.pt')\n",
    "\n",
    "out_dir = expanduser('~/myData/aae/out_aae_{}'.format(model_name))\n",
    "mkdir_p(out_dir)\n",
    "\n",
    "\n",
    "# In[4]:\n",
    "\n",
    "\n",
    "discard_list = ['freq_010-P006-vid_001', \n",
    "                'P009', \n",
    "                'freq_004-P011-vid_001', \n",
    "                'freq_004-P013', \n",
    "                \n",
    "                'freq_010-P008-vid_002', \n",
    "                'freq_004-P015-vid_002', \n",
    "                'freq_004-P015-vid_002', \n",
    "                'freq_010-P015-vid_001', \n",
    "                'freq_010-P016-vid_001', \n",
    "                'freq_010-P017-vid_001', \n",
    "                'freq_010-P020-vid_001', \n",
    "                'freq_010-P020-vid_002', \n",
    "                'freq_010-P022-vid_001', \n",
    "                'freq_010-P022-vid_002', \n",
    "                'freq_010-P023-vid_001', \n",
    "                \n",
    "                'uvseg_amp_5-pos_1-freq_004-P016-vid_002', #out of FOV\n",
    "                'uvseg_amp_5-pos_1-freq_010-P016-vid_001_frame_002161-002225',\n",
    "                'uvseg_amp_5-pos_1-freq_010-P016-vid_001_frame_002177-002241',\n",
    "                'uvseg_amp_5-pos_1-freq_010-P016-vid_001_frame_002193-002257',\n",
    "                'uvseg_amp_5-pos_1-freq_010-P016-vid_001_frame_002209-002273',\n",
    "                'uvseg_amp_5-pos_1-freq_010-P016-vid_001_frame_002225-002289',\n",
    "                'uvseg_amp_5-pos_1-freq_010-P016-vid_001_frame_002241-002305',\n",
    "                'uvseg_amp_5-pos_1-freq_010-P016-vid_001_frame_002257-002321',\n",
    "                'uvseg_amp_5-pos_1-freq_010-P016-vid_001_frame_002273-002337',\n",
    "                'uvseg_amp_5-pos_1-freq_010-P029-vid_001', # too dark to see motion\n",
    "                'uvseg_amp_5-pos_1-freq_010-P029-vid_002'\n",
    "               ]\n",
    "\n",
    "nz = 10 # size of latent vector --> action type. TODO: 2d enough?\n",
    "slr_fac = 0.03\n",
    "\n",
    "cuda = True\n",
    "lr = 1e-4\n",
    "batch_size = 64 #8*num_gpus # number of segments in each batch\n",
    "in_size = 64\n",
    "\n",
    "fps = 30\n",
    "ns = 2 # time series length (in seconds)\n",
    "nfrm = ns * fps + 4 #time series length (in number of frames) #also make it 64\n",
    "nc = 2 # number of channels (each frm in series has theta & rad)\n",
    "ngf = 64 # decoder (generator) filter factor\n",
    "ndf = 64 # encoder filter factor\n",
    "h_dim = 128 # discriminator hidden size\n",
    "lam = 1 # regulization coefficient\n",
    "n_labels = 3 # total number of freq labels\n",
    "\n",
    "\n",
    "# In[5]:\n",
    "\n",
    "\n",
    "class Decoder3D_yz(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Decoder3D_yz, self).__init__()\n",
    "\n",
    "        # state size. (nc) x 64 x 64, from y & z separately\n",
    "        self.convt_y = nn.ConvTranspose3d(n_labels, ngf*8, kernel_size=4, stride=1, padding=0, bias=False)\n",
    "        self.convt_z = nn.ConvTranspose3d(nz, ngf*8, kernel_size=4, stride=1, padding=0, bias=False)\n",
    "        self.bn1 = nn.BatchNorm3d(ngf * 8)\n",
    "        # state size. (ngf*8) x 4 x 4\n",
    "        self.convt2 = nn.ConvTranspose3d(ngf*8, ngf*4, kernel_size=4, stride=2, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm3d(ngf * 4)\n",
    "        # state size. (ngf*4) x 8 x 8\n",
    "        self.convt3 = nn.ConvTranspose3d(ngf * 4, ngf*2, kernel_size=4, stride=2, padding=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm3d(ngf * 2)\n",
    "        # state size. (ngf*2) x 16 x 16\n",
    "        self.convt4 = nn.ConvTranspose3d(ngf*2,  ngf, kernel_size=4, stride=2, padding=1, bias=False)\n",
    "        self.bn4 = nn.BatchNorm3d(ngf)\n",
    "        # state size. (ngf) x 32 x 32\n",
    "        self.convt5 = nn.ConvTranspose3d(ngf, nc, kernel_size=4, stride=2, padding=1, bias=False)\n",
    "        \n",
    "    def forward(self, y, z):\n",
    "        x_from_y = self.convt_y(y)\n",
    "        x_from_z = self.convt_z(z)\n",
    "        x = x_from_y + x_from_z\n",
    "        x = self.bn1(x)\n",
    "        x = F.relu(x, True)\n",
    "        x = self.convt2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = F.relu(x, True)\n",
    "        x = self.convt3(x)\n",
    "        x = self.bn3(x)\n",
    "        x = F.relu(x, True)\n",
    "        x = self.convt4(x)\n",
    "        x = self.bn4(x)\n",
    "        x = F.relu(x, True)\n",
    "        x = self.convt5(x)\n",
    "        x = F.sigmoid(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# In[6]:\n",
    "\n",
    "\n",
    "class Encoder3D_yz(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Encoder3D_yz, self).__init__()\n",
    "        # input is (nc=2 [u,v]) nfrm x 64 x 64 \n",
    "        self.conv1 = nn.Conv3d(nc, ndf, kernel_size=4, stride=2, padding=1, bias=False)\n",
    "        # state size. (ndf) x 32 x 32\n",
    "        self.conv2 = nn.Conv3d(ndf, ndf * 2, kernel_size=4, stride=2, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm3d(ndf * 2)\n",
    "        # state size. (ndf*2) x 16 x 16\n",
    "        self.conv3 = nn.Conv3d(ndf * 2, ndf * 4, kernel_size=4, stride=2, padding=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm3d(ndf * 4)\n",
    "        # state size. (ndf*4) x 8 x 8\n",
    "        self.conv4 = nn.Conv3d(ndf * 4, ndf * 8, kernel_size=4, stride=2, padding=1, bias=False)\n",
    "        self.bn4 = nn.BatchNorm3d(ndf * 8)\n",
    "        # separate y & z\n",
    "        self.conv_y = nn.Conv3d(ndf * 8, n_labels, kernel_size=4, stride=1, padding=0, bias=False)\n",
    "        self.softmax_y = nn.Softmax()\n",
    "                           \n",
    "    def forward(self, x, print_size = False):\n",
    "        if print_size:\n",
    "            print('\\t\\tIn Model: input size {}'.format(x.size()))    \n",
    "        x = self.conv1(x)\n",
    "        x = F.leaky_relu(x, 0.2, inplace=True)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = F.leaky_relu(x, 0.2, inplace=True)\n",
    "        x = self.conv3(x)\n",
    "        x = self.bn3(x)\n",
    "        x = F.leaky_relu(x, 0.2, inplace=True)\n",
    "        x = self.conv4(x)\n",
    "        x = self.bn4(x)\n",
    "        x = F.leaky_relu(x, 0.2, inplace=True)\n",
    "        y = self.conv_y(x)\n",
    "        y = F.softmax(y)\n",
    "        if print_size:\n",
    "            print('\\t\\tIn Model: output y size {}'.format(y.size()))\n",
    "        return y\n",
    "\n",
    "\n",
    "# In[7]:\n",
    "\n",
    "\n",
    "def plot_and_save_segment_images(samples, out_dir, fig_title, convert=False):    \n",
    "    ncols = 8\n",
    "    nrows = int(np.ceil(samples.shape[1]/8.)) \n",
    "    sub_plot_sz = 3.5\n",
    "    fig = plt.figure(figsize=(sub_plot_sz*ncols, sub_plot_sz*nrows))\n",
    "    gs = gridspec.GridSpec(nrows, ncols)\n",
    "    gs.update(wspace=0.05, hspace=0.05)\n",
    "    \n",
    "    for i in range(8): #range(samples.shape[1]):  \n",
    "        ax = plt.subplot(gs[i])\n",
    "        plt.axis('off')\n",
    "        ax.set_xticklabels([])\n",
    "        ax.set_yticklabels([])\n",
    "        ax.set_aspect('equal')\n",
    "        sub_fig_title = fig_title \n",
    "        ax.set_title(sub_fig_title)\n",
    "        \n",
    "        img = np.zeros((samples.shape[2], samples.shape[3], 3), dtype=np.float32)\n",
    "        img[:,:,1] = samples[0, i, :, :]\n",
    "        img[:,:,2] = samples[1, i, :, :]\n",
    "        \n",
    "        plt.imshow(img)\n",
    "        \n",
    "    if not os.path.exists(out_dir):\n",
    "            os.makedirs(out_dir)\n",
    "    plt.savefig('{}/{}.png'.format(out_dir, fig_title), bbox_inches='tight')\n",
    "    plt.show()\n",
    "    plt.close(fig)\n",
    "\n",
    "\n",
    "# In[8]:\n",
    "\n",
    "\n",
    "def plot_and_save_batch_images(samples, out_dir, fig_title, y = None, convert=False):\n",
    "    if convert:\n",
    "        if cuda:\n",
    "            samples = samples.cpu()\n",
    "        samples = samples.data.numpy() \n",
    "        \n",
    "    for seg_idx in range(1): #range(samples.shape[0]):\n",
    "        if y is not None:\n",
    "            fig_title += '_y:{}'.format(y[seg_idx])\n",
    "        plot_and_save_segment_images(samples[seg_idx], out_dir, fig_title) #'{}_s{}'.format(fig_title, seg_idx))\n",
    "\n",
    "\n",
    "# In[9]:\n",
    "\n",
    "\n",
    "def plot_losses_and_save_fig(S_losses, train_accuracies, val_accuracies, test_accuracies, out_dir, fig_title_prefix):\n",
    "    save_pkl({'test_acc': test_accuracies, \n",
    "              'val_acc': val_accuracies,\n",
    "              'train_acc': train_accuracies, \n",
    "              'S': S_losses\n",
    "             }, \n",
    "             '{}/{}_loss_data.pkl'.format(out_dir, fig_title_prefix))\n",
    "\n",
    "    plt.figure(figsize=(12, 36))\n",
    "    \n",
    "    ax = plt.subplot(4,1,1)\n",
    "    ax.set_title('{}_Supervise_loss'.format(fig_title_prefix))\n",
    "    plt.plot(S_losses)\n",
    "    \n",
    "    ax = plt.subplot(4,1,2)\n",
    "    ax.set_title('{}_Train_Accuracy'.format(fig_title_prefix))\n",
    "    plt.plot(train_accuracies)\n",
    "\n",
    "    ax = plt.subplot(4,1,3)\n",
    "    ax.set_title('{}_Val_Accuracy'.format(fig_title_prefix))\n",
    "    plt.plot(val_accuracies)\n",
    "    \n",
    "    ax = plt.subplot(4,1,4)\n",
    "    ax.set_title('{}_Test_Accuracy'.format(fig_title_prefix))\n",
    "    plt.plot(test_accuracies)\n",
    "\n",
    "    plt.savefig('{}/{}_loss.png'.format(out_dir, fig_title_prefix), bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# In[10]:\n",
    "\n",
    "\n",
    "def calculate_accuracy_batches(data_loader, Q):\n",
    "    tp = 0  \n",
    "    tot = 0\n",
    "    for batch_idx, (data, batch_Y, y_onehot, _, _) in enumerate(data_loader):\n",
    "        curr_batch_size = len(batch_Y)\n",
    "        X = data.to(device)              \n",
    "        y_onehot = y_onehot.to(device)\n",
    "            \n",
    "        y_onehot_ = Q(X)\n",
    "        \n",
    "        y_ = np.argmax(y_onehot_.cpu().detach().view(curr_batch_size,-1).numpy(), axis=1)\n",
    "        batch_Y = batch_Y.cpu().data.numpy() \n",
    "#         print('y_onehot = {}'.format(y_onehot.cpu().detach().view(curr_batch_size,-1).numpy()))\n",
    "#         print('y_onehot_ = {}'.format(y_onehot_.cpu().detach().view(curr_batch_size,-1).numpy()))\n",
    "#         print('type(y_){}   y_:{}'.format(type(y_), y_))\n",
    "#         print('type(y){}   y :{}'.format(type(batch_Y), batch_Y))\n",
    "#        print('current tp = {}'.format(np.sum(y_ == batch_Y)))\n",
    "        tp += np.sum(y_ == batch_Y)\n",
    "        tot += len(batch_Y)\n",
    "    \n",
    "#    print('tp = {}, tot_num = {}, acc = {}'.format(tp, tot, float(tp)/tot))\n",
    "    return float(tp)/tot\n",
    "\n",
    "def calculate_accuracy(train_loader, val_loader, test_loader, Q):\n",
    "    train_acc = calculate_accuracy_batches(train_loader, Q)\n",
    "    val_acc = calculate_accuracy_batches(val_loader, Q)\n",
    "    test_acc = calculate_accuracy_batches(test_loader, Q)\n",
    "    return train_acc, val_acc, test_acc\n",
    "\n",
    "\n",
    "# In[11]:\n",
    "\n",
    "\n",
    "print('Use {} GPUs'.format(num_gpus))\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "# In[12]:\n",
    "\n",
    "\n",
    "import collections\n",
    "Q = Encoder3D_yz()\n",
    "trained_P = Decoder3D_yz()\n",
    "   \n",
    "trained_P = nn.DataParallel(trained_P)    \n",
    "if gen_model_fpath is not None and exists(gen_model_fpath):\n",
    "    print('loading pretrained generator ... {}'.format(gen_model_fpath))\n",
    "    trained_P.load_state_dict(torch.load(gen_model_fpath))\n",
    "else:\n",
    "    print('WARNING: no pretrained generator loaded')\n",
    "    \n",
    "cont_model_qpath = cont_model_fpath.format('Q')\n",
    "if exists(cont_model_qpath):\n",
    "    print('loading continue model... {}'.format(cont_model_qpath))\n",
    "    loaded_model = torch.load(cont_model_qpath)  \n",
    "    print('loaded_model keys = {}'.format(loaded_model.keys()))\n",
    "    if 'module.' in loaded_model.keys()[0]: #trained using DataParallel\n",
    "        print('loading parallel model ...')\n",
    "        Q = nn.DataParallel(Q)                      \n",
    "    Q.load_state_dict(loaded_model)\n",
    "else:\n",
    "    if init_model_fpath is not None and exists(init_model_fpath):\n",
    "        print('loading initial model... {}'.format(init_model_fpath))\n",
    "        loaded_model = torch.load(init_model_fpath)\n",
    "        if 'module.' in list(loaded_model.keys())[0]: #trained using DataParallel\n",
    "            print('loading parallel model ...')\n",
    "            Q = nn.DataParallel(Q)\n",
    "            Q.load_state_dict(loaded_model)   \n",
    "        else:\n",
    "            Q.load_state_dict(loaded_model)   \n",
    "            Q = nn.DataParallel(Q)\n",
    "    else:\n",
    "        print('WARNING: no initial model loaded')\n",
    "    \n",
    "Q = Q.to(device)\n",
    "trained_P = trained_P.to(device)                                                  \n",
    "   \n",
    "def reset_grad():\n",
    "    Q.zero_grad()\n",
    "    \n",
    "Qsup_solver = optim.Adam(Q.parameters(), lr=slr_fac*lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# In[13]:\n",
    "\n",
    "\n",
    "def tensor_to_value(t_var):\n",
    "    if cuda:\n",
    "        t = t_var.cpu()\n",
    "    else:\n",
    "        t = t_var\n",
    "        \n",
    "    return t.data.numpy()\n",
    "\n",
    "\n",
    "# In[14]:\n",
    "\n",
    "\n",
    "S_losses = []\n",
    "train_accuracies = []\n",
    "val_accuracies = []\n",
    "test_accuracies = []\n",
    "\n",
    "est = pytz.timezone('US/Eastern')\n",
    "print('Time Zone: {}'.format(est))\n",
    "est_time = datetime.now(est)\n",
    "print('default format: {}'.format(est_time))\n",
    "\n",
    "train_loader = DataLoader(dataset=OflowDlDataset(dl_path=train_fpath,\n",
    "                                                 data_info_path=data_info_path,\n",
    "                                                 pkl_root = pkl_root,\n",
    "                                                 discard_list = discard_list,\n",
    "                                                 no_aug_ratio = 1.0,\n",
    "                                                 seg_random_seed=123),\n",
    "                          batch_size = batch_size, \n",
    "                          num_workers = num_gpus, \n",
    "                          shuffle = True)\n",
    "\n",
    "train_loader_aug = DataLoader(dataset=OflowDlDataset(dl_path=train_fpath,\n",
    "                                                 data_info_path=data_info_path,\n",
    "                                                 pkl_root = pkl_root,\n",
    "                                                 discard_list = discard_list,\n",
    "                                                 no_aug_ratio = 0.0,\n",
    "                                                 seg_random_seed=123),\n",
    "                          batch_size = batch_size, \n",
    "                          num_workers = num_gpus, \n",
    "                          shuffle = True)\n",
    "\n",
    "val_loader = DataLoader(dataset=OflowDlDataset(dl_path=val_fpath,\n",
    "                                                data_info_path=data_info_path, \n",
    "                                                pkl_root = pkl_root\n",
    "                                               ),\n",
    "                          batch_size = batch_size, \n",
    "                          num_workers = num_gpus, \n",
    "                          shuffle = False)\n",
    "\n",
    "test_loader = DataLoader(dataset=OflowDlDataset(dl_path=test_fpath,\n",
    "                                                data_info_path=data_info_path, \n",
    "                                                pkl_root = pkl_root\n",
    "                                               ),\n",
    "                          batch_size = batch_size, \n",
    "                          num_workers = num_gpus, \n",
    "                          shuffle = False)\n",
    "\n",
    "\n",
    "# In[15]:\n",
    "\n",
    "\n",
    "def train_classify_network(X, y_onehot, convert = True):\n",
    "    \"\"\"\n",
    "    train supervised classification with augmented data to avoid artifacts effect in Q,P\n",
    "    \"\"\"\n",
    "    if convert:\n",
    "        X = Variable(X)    \n",
    "        X = X.to(device)\n",
    "    \n",
    "    y_onehot = y_onehot.to(device)\n",
    "    \n",
    "    curr_batch_size = X.size()[0]\n",
    "    \n",
    "    y_predict = Q(X)\n",
    "    S_loss = F.binary_cross_entropy_with_logits(input=y_predict.view(curr_batch_size,-1), target=y_onehot)\n",
    "    S_loss.backward()\n",
    "    Qsup_solver.step()\n",
    "    reset_grad()\n",
    "    \n",
    "    return S_loss\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "num_of_batches = len(train_loader)\n",
    "print('batch len = {}'.format(num_of_batches))\n",
    "print_size = False\n",
    "\n",
    "max_val_acc = 0.0\n",
    "it_sum = 0\n",
    "\n",
    "for it in range(start_it, 100000, 1): \n",
    "    \"\"\"\n",
    "    Training: except regularization phase, all the other phases in training updates Q parameters \n",
    "    \"\"\"\n",
    "    # data augmentation\n",
    "    if it > start_it and it % 2 == 1: #use real image first\n",
    "        for batch_idx, (data, batch_Y, y_onehot, _, augs) in enumerate(train_loader_aug):\n",
    "            S_loss = train_classify_network(data, y_onehot, convert = True)\n",
    "            \n",
    "            if it % 100 == 1:\n",
    "                plot_and_save_batch_images(data, out_dir=out_dir, fig_title='{0}_sup_aug_y'.format(it), y=batch_Y)\n",
    "    \n",
    "    # generator \n",
    "    if it > start_it and it % 2 == 0: #use real image first\n",
    "        for gen_i in range(num_of_batches-1):\n",
    "            curr_batch_size = batch_size\n",
    "            \n",
    "            z_gen = Variable(torch.randn(curr_batch_size, nz)) #gaussian distribution \n",
    "            \n",
    "            # randomly generate y: 0.3 freq000, 0.3 freq004, 0.4 freq010 since fewer freq010 real data\n",
    "            y_gen = np.random.randint(low = 0, high = 10, size = curr_batch_size)\n",
    "            y_gen = [0 if e <= 2 else 1 if e<=5 else 2 for e in list(y_gen)] \n",
    "            y_onehot_gen = np.zeros(shape = (curr_batch_size, n_labels), dtype=np.float32)\n",
    "            y_onehot_gen[np.array(range(curr_batch_size)), np.array(y_gen)] = 1.\n",
    "            y_onehot_gen = torch.from_numpy(y_onehot_gen)\n",
    "        \n",
    "            z_gen = z_gen.unsqueeze(2).unsqueeze(3).unsqueeze(4) # add 2 dimensions            \n",
    "            z_gen = z_gen.to(device)\n",
    "            \n",
    "            X_gen = trained_P(y_onehot_gen.unsqueeze(2).unsqueeze(3).unsqueeze(4).to(device), z_gen)\n",
    "            \n",
    "            # supervised training using generated images\n",
    "            S_loss = train_classify_network(X_gen, y_onehot_gen, convert = False)\n",
    "            \n",
    "            if it == 2 or it % 100 == 0:\n",
    "                plot_and_save_batch_images(X_gen, out_dir=out_dir, fig_title='{0}_sup_syn_y'.format(it), y=y_gen, convert=True)    \n",
    "                \n",
    "    for batch_idx, (data, batch_Y, y_onehot, _, _) in enumerate(train_loader):\n",
    "        curr_batch_size = data.size()[0]       \n",
    "                \n",
    "        if it == start_it and batch_idx == 0:\n",
    "            print('\\tOutside Model, input size {}'.format(data.size()))\n",
    "            print_size = True   \n",
    "                    \n",
    "        # supervised classification phase\n",
    "        S_loss = train_classify_network(data, y_onehot, convert = True)\n",
    "        \n",
    "        if it == start_it and batch_idx == 0:\n",
    "            print_size = False   \n",
    "         \n",
    "        if batch_idx == num_of_batches-1:\n",
    "            S_losses.append(tensor_to_value(S_loss))\n",
    "            train_acc, val_acc, test_acc = calculate_accuracy(train_loader, val_loader, test_loader, Q)\n",
    "            train_accuracies.append(train_acc)\n",
    "            val_accuracies.append(val_acc)\n",
    "            test_accuracies.append(test_acc)\n",
    "   \n",
    "        # Print and plot every now and then\n",
    "        if it % 1 == 0 and batch_idx == num_of_batches-1:\n",
    "            est_time = datetime.now(est)\n",
    "            if val_acc > max_val_acc:\n",
    "                max_val_acc = val_acc\n",
    "                it_sum = 0\n",
    "                \n",
    "                # save model\n",
    "                if it > it_tolerance: #not save too many models at the beginning\n",
    "                    torch.save(Q.state_dict(), join(model_path, \"{}_{}_Q_best.pt\".format(model_name, it))) \n",
    "                    with open(join(out_dir, 'aae_iter_{}_acc.txt'.format(it)), 'w') as f:\n",
    "                              f.write('train_acc: {}, val_acc: {}, test_acc: {}\\n'.format(train_acc, val_acc, test_acc))\n",
    "            else:\n",
    "                if it_sum > it_tolerance:\n",
    "                    break\n",
    "                it_sum += 1\n",
    "                \n",
    "            print('Iter-{} Batch-{}: {}, S_loss: {:.3}; train_acc: {:.3}; val_acc: {:.3}; test_acc: {:.3}, it_sum={}'\n",
    "              .format(it, batch_idx, est_time, S_loss.data[0], train_acc, val_acc, test_acc, it_sum))\n",
    "                       \n",
    "        if it > start_it and it % 100 == 0 and batch_idx == num_of_batches-1: #at the end of each iteration\n",
    "            #plot loss curve\n",
    "            plot_losses_and_save_fig(S_losses, train_accuracies, val_accuracies, test_accuracies, out_dir=out_dir, \n",
    "                                     fig_title_prefix='Plot_Iter_{}'.format(it)\n",
    "                                    )\n",
    "            \n",
    "            plot_and_save_batch_images(data, out_dir=out_dir, fig_title='Img{0}_uv_y'.format(it), y=batch_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch_p36]",
   "language": "python",
   "name": "conda-env-pytorch_p36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
